## Writing ml & dl algos from scratch for educational purposes and fun :) 

Inspired by Karpathy's youtube playlist, I decided to embark on a quest to work on the foundational building blocks of machine learning. 
Working from the foundations and upwards has always been a very constructive experience for me. Low level implementations provide unique insights and challenges, that usually hide behind frameworks and APIs. This is my quest towards a deeper understanding of the field I feel so passionate about.

I strive to work on the solutions without external support as much as possible. When stuck, I will consult external resources to get hints, but will avoid pasting other people's code. 

Repo is under ongoing construction. 


### Implemented:

##### ML algorithms
- N-grams &#9745; 
  
##### DL architectures
- Neuron &#9745; 
- Feedforward Net &#9745; 

##### engine 
- A scalar "Tensor" class
- The Backpropagation algorithm

#### Roadmap: 
- Design Neuron & FFC layer functionality          &#9745; 
- Create Scalar "Tensor" class                     &#9745; 
- Implement backpropagation algo for scalars       &#9745;
- Expand Tensor class to multiple dimensions       &#9744; 
- Support backprop for multiple dim tensors        &#9744; 
- Train Feedforward layer                          &#9744; 